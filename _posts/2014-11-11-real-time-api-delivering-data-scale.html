---
layout: post
title: Real Time API delivering data @ Scale
date: '2014-11-11T05:18:00.000-08:00'
author: Akash Mishra
tags:
- Java
- hadoop
- hive
- API
modified_time: '2014-11-14T06:33:09.939-08:00'
thumbnail: http://2.bp.blogspot.com/-IENyiyIIvKY/U1t_s9S5UpI/AAAAAAAAATs/XNCWmM2J6Ac/s72-c/Akash.png
blogger_id: tag:blogger.com,1999:blog-5454104814334713963.post-6310193154732816958
blogger_orig_url: http://sleepythread.blogspot.com/2014/11/real-time-api-delivering-data-scale.html
---

<div dir="ltr" style="text-align: left;" trbidi="on"><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">This post talks about various architectural decision and their driving reasons which was taken to build an REST API which need to deliver large amount of reporting data. </span><br /><br /><h3 style="text-align: left;"><span style="font-family: inherit;">API Overview</span></h3><ul style="text-align: left;"><li><span style="font-family: inherit;">REST Based API.</span></li><li><span style="font-family: inherit;">API should respond with various different type of report. Each of this report are in order of TB's.</span></li><li><span style="font-family: inherit;">Response of each API calls is a ZIP file containing data. Each ZIP files are in order of 10-40 M.B's.&nbsp;</span></li><li><span style="font-family: inherit;">Sample API Queries are&nbsp;</span></li><ul><li><span style="font-family: inherit;">?start-date=2012-10-01&amp;end-date=2012-10-29&amp;customer=1&amp;aggregate-by=state,city</span></li></ul></ul><h3 style="text-align: left;"><span style="font-family: inherit;">&nbsp;Key System Requirement</span></h3><ul style="text-align: left;"><li><span style="font-family: inherit;">API caller should be able to filter and aggregate data on various different parameter's.&nbsp;</span></li><li><span style="font-family: inherit;">These response should be in Real Time. [S.L.A 1-3 min].</span></li><li><span style="font-family: inherit;">&nbsp;Security</span></li><ul><li><span style="font-family: inherit;">API should be very secured as data need to be served are private and confidential.</span></li><li><span style="font-family: inherit;">API should make sure that on caller should never be able to obtain data of other caller.</span></li></ul><li><span style="font-family: inherit;">Scalability</span></li><ul><li><span style="font-family: inherit;">We need to design our architecture such that if we want to add more caller to our API,&nbsp; we just need to add more hardware. There should not be any software change for adding more customer for API.&nbsp; </span></li></ul></ul><br /><span style="font-family: inherit;"><span style="font-family: inherit;">I</span>nitial set of requirement gives us a clear indication that this a <b>Big D<span style="font-family: inherit;">ata</span></b> problem as we need to deal with large amount of data which will definitely grow with time. Even with a stable Big Data Ecosystem like Hadoop, some of the&nbsp; key requirements with our application was restricting us to use Big Data stack like Hadoop.&nbsp;</span><br /><br /><span style="font-family: inherit;">Before talking about our approach<span style="font-family: inherit;">, <span style="font-family: inherit;">l</span></span>et us first compare Big Data Stack like Hadoop/Hive and RDBMS on various <span style="font-family: inherit;">parameters</span>,</span><br /><br /><ol style="text-align: left;"><li><b><span style="font-family: inherit;">Handling amount of Data [In order of T.B's and P.B's]</span></b></li><ol><li><span style="font-family: inherit;">&nbsp;Hive/Hadoop: Hi<span style="font-family: inherit;">ve<span style="font-family: inherit;">/Hadoop are well <span style="font-family: inherit;">know fo<span style="font-family: inherit;">r handli<span style="font-family: inherit;">ng <span style="font-family: inherit;">growing dat<span style="font-family: inherit;">a in <span style="font-family: inherit;">order <span style="font-family: inherit;">of <span style="font-family: inherit;">T.B's &amp; P.B's<span style="font-family: inherit;">. <span style="font-family: inherit;">When your data grows<span style="font-family: inherit;">, you need to add more mach<span style="font-family: inherit;">ine into cluster. There needs to be no changes in code<span style="font-family: inherit;">.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li><li><span style="font-family: inherit;">&nbsp;RDBMS: Tradit<span style="font-family: inherit;">ional Database sy<span style="font-family: inherit;">ste<span style="font-family: inherit;">m are <span style="font-family: inherit;">not t<span style="font-family: inherit;">oo g<span style="font-family: inherit;">oo<span style="font-family: inherit;">d at handl<span style="font-family: inherit;">ing the data in order of T.B's and P.B's.<span style="font-family: inherit;"> <span style="font-family: inherit;">We need to <span style="font-family: inherit;">explicit</span> <span style="font-family: inherit;">handle <span style="font-family: inherit;">the data <span style="font-family: inherit;">gr<span style="font-family: inherit;">owth </span></span></span></span></span></span></span></span></span></span></span></span></span></span>by some <span style="font-family: inherit;">mechanisms like Horizontal partitioning. This leads to change in Application Code<span style="font-family: inherit;">.&nbsp;&nbsp; </span></span></span></li></ol><li><span style="font-family: inherit;">&nbsp;<b>Real Time Interactive Filtering/Querying</b></span></li><ol><li><span style="font-family: inherit;">Hive/Hadoop: Hadoop<span style="font-family: inherit;">/<span style="font-family: inherit;">H<span style="font-family: inherit;">ive<span style="font-family: inherit;"> <span style="font-family: inherit;">is not su<span style="font-family: inherit;">itable <span style="font-family: inherit;">for low latency query<span style="font-family: inherit;">. Query li<span style="font-family: inherit;">ke simple filtering can take in order of minutes to hour in Hadoop/Hive<span style="font-family: inherit;">.</span></span></span></span></span></span></span></span></span></span></span></li><li><span style="font-family: inherit;">RDBMS:<span style="font-family: inherit;"> The<span style="font-family: inherit;">se sy<span style="font-family: inherit;">stem are well know for the<span style="font-family: inherit;">ir sub-second to second<span style="font-family: inherit;">s response times. </span></span></span></span></span></span></li></ol><li><span style="font-family: inherit;">&nbsp;<b>Join's between large tables [ millions X millions X millions ]</b></span></li><ol><li><span style="font-family: inherit;">Hive/Hadoop: Hive/Hadoop han<span style="font-family: inherit;">dle's <span style="font-family: inherit;">large join <span style="font-family: inherit;">very well<span style="font-family: inherit;">. <span style="font-family: inherit;">Hadoop/Hive<span style="font-family: inherit;"> automatically handles <span style="font-family: inherit;">these large joins. The exec<span style="font-family: inherit;">ution time inc<span style="font-family: inherit;">rese<span style="font-family: inherit;">s wi<span style="font-family: inherit;">th <span style="font-family: inherit;">more n<span style="font-family: inherit;">umber of records <span style="font-family: inherit;">but no <span style="font-family: inherit;">explicit</span> handl<span style="font-family: inherit;">ing re<span style="font-family: inherit;">quired<span style="font-family: inherit;">. </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li><li><span style="font-family: inherit;">RDBMS:<span style="font-family: inherit;"> <span style="font-family: inherit;">These system<span style="font-family: inherit;"> <span style="font-family: inherit;">have so<span style="font-family: inherit;">me performance issue while doing join<span style="font-family: inherit;">'s and hence Join's are <span style="font-family: inherit;">usually avoided in RDBMS<span style="font-family: inherit;">.</span></span> </span></span></span></span></span></span></span></li></ol><li><span style="font-family: inherit;">&nbsp;<b>Access/Security Control</b></span></li><ol><li><span style="font-family: inherit;">Hive/Haoo<span style="font-family: inherit;">p<span style="font-family: inherit;">: There <span style="font-family: inherit;">is <span style="font-family: inherit;">sti<span style="font-family: inherit;">ll no strong access and security control present in the Bi<span style="font-family: inherit;">g Data <span style="font-family: inherit;">syste<span style="font-family: inherit;">m. There are so<span style="font-family: inherit;">me very basic <span style="font-family: inherit;">control but no<span style="font-family: inherit;">t </span></span></span></span></span></span></span></span></span></span></span></span><span data-dobid="hdw">suitable</span><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"> for&nbsp; </span></span></span></span></span></span></span></span>high <span style="font-family: inherit;">security appl<span style="font-family: inherit;">ication<span style="font-family: inherit;">s.&nbsp;</span></span></span></span></span></span></span></span></span></li><li><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;">RDBMS: These system has <span style="font-family: inherit;">st<span style="font-family: inherit;">rong access control and security system build in<span style="font-family: inherit;">to them. <span style="font-family: inherit;">There are vari<span style="font-family: inherit;">ous<span style="font-family: inherit;"> authentication<span style="font-family: inherit;"> and <span style="font-family: inherit;">authorization mech<span style="font-family: inherit;">anism provided by these sy<span style="font-family: inherit;">stem.&nbsp;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> </span></li></ol><li><span style="font-family: inherit;">&nbsp;<b>Resilient to Hardware failure and Auto Scaling</b></span></li><ol><li><span style="font-family: inherit;">Hive/Hadoop: <span style="font-family: inherit;"><span style="font-family: inherit;"><span style="font-family: inherit;">Resilient to failure and <span style="font-family: inherit;">auto scaling is <span style="font-family: inherit;">centric to <span style="font-family: inherit;">design o<span style="font-family: inherit;">f Hadoop. It is well capable of handl<span style="font-family: inherit;">ing the failure.</span>&nbsp;</span></span></span></span></span> </span></span></span></li><li><span style="font-family: inherit;">RDBMS:These syste<span style="font-family: inherit;">m <span style="font-family: inherit;">are not well ca<span style="font-family: inherit;">pable <span style="font-family: inherit;">of managing with hardware <span style="font-family: inherit;">failure.<span style="font-family: inherit;"> <span style="font-family: inherit;">There are some ways in which these syste<span style="font-family: inherit;">m can be made fault <span style="font-family: inherit;">tolerant<span style="font-family: inherit;"></span> but required ext<span style="font-family: inherit;">ernal intervention for<span style="font-family: inherit;"> getting system back<span style="font-family: inherit;">. Also the runni<span style="font-family: inherit;">ng proces<span style="font-family: inherit;">s will be lost. </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li></ol><li><span style="font-family: inherit;">&nbsp;<b>Fast read operation's</b></span></li><ol><li><span style="font-family: inherit;">Hadoop/Hive: Hadoop/Hive doesn't perform<span style="font-family: inherit;"> well in <span style="font-family: inherit;">fast random read operation's. <span style="font-family: inherit;">The<span style="font-family: inherit;">re are some Big Data <span style="font-family: inherit;">system like HBase which helps in fast read operation<span style="font-family: inherit;"> but <span style="font-family: inherit;">has lots of <span style="font-family: inherit;">limi<span style="font-family: inherit;">tations<span style="font-family: inherit;">.</span></span></span></span></span></span></span></span></span></span></span></li><li><span style="font-family: inherit;">RDBMS:<span style="font-family: inherit;"> can effectivel<span style="font-family: inherit;">y handle <span style="font-family: inherit;">most type o<span style="font-family: inherit;">f read operation with response time in order of <span style="font-family: inherit;">sub sec<span style="font-family: inherit;">s. </span></span></span></span></span></span></span></li></ol></ol><br /><span style="font-family: inherit;"><span style="font-family: inherit;">As it is ev<span style="font-family: inherit;">ident th<span style="font-family: inherit;">at</span></span></span> some <span style="font-family: inherit;">of our system <span style="font-family: inherit;">requirements</span></span> are supported by&nbsp; RDBMS and some are supported by Big Data Ecosystem. Hence, we took a Hybrid Approach for our Application. <span style="font-family: inherit;">We</span> used Big Data as well as convention RDBMS for our API. In our <span style="font-family: inherit;"><span style="font-family: inherit;">approach, we ha<span style="font-family: inherit;">ve used Hadoop to <span style="font-family: inherit;">de-normalize&nbsp; </span>the data <span style="font-family: inherit;">and transform it into <span style="font-family: inherit;"><span style="font-family: inherit;">state where it is easy for RDBMS system to perform read ope<span style="font-family: inherit;">ration</span></span>. <span style="font-family: inherit;">We create <span style="font-family: inherit;">variou<span style="font-family: inherit;">s <span style="font-family: inherit;">data <span style="font-family: inherit;">partitions in flat table structure whi<span style="font-family: inherit;">ch he<span style="font-family: inherit;">lp R<span style="font-family: inherit;">DBMS system<span style="font-family: inherit;"> to <span style="font-family: inherit;">effectively filter and aggregate the results as per user request. </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">On Very High level the architecture of the proposed API is as follows,</span><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-IENyiyIIvKY/U1t_s9S5UpI/AAAAAAAAATs/XNCWmM2J6Ac/s1600/Akash.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-IENyiyIIvKY/U1t_s9S5UpI/AAAAAAAAATs/XNCWmM2J6Ac/s1600/Akash.png" height="480" width="640" /></a></div><br /><br /><br /><span style="font-family: inherit;">&nbsp;Architecture is broadly divided into two main parts,</span><br /><ol style="text-align: left;"><li><span style="font-family: inherit;">Big Data system.</span></li><li><span style="font-family: inherit;">Traditional<span style="font-family: inherit;">(</span>RDBMS) based Java API.</span></li></ol><h4 style="text-align: left;"><span style="font-family: inherit;">1. Big Data system:</span></h4><span style="font-family: inherit;">This section deals with all the Batch processing for the given API. This sections deals with lots of Heavy Lifting like costly join's e.t.c. Also the data is <span style="font-family: inherit;">partitioned</span> <span style="font-family: inherit;">based on <span style="font-family: inherit;">API user in Hive. This helps in effect<span style="font-family: inherit;">ively reducing the data w<span style="font-family: inherit;">hic<span style="font-family: inherit;">h n<span style="font-family: inherit;">eed to be processed by RDBMS system for each API call. When data gro<span style="font-family: inherit;">ws<span style="font-family: inherit;">, Hive can automatically create more partitions w<span style="font-family: inherit;">ithout changing the <span style="font-family: inherit;">Application<span style="font-family: inherit;"> code. </span></span></span></span></span></span></span></span></span></span></span></span><br /><h4 style="text-align: left;"><span style="font-family: inherit;">2. Traditional RDBMS:</span></h4><span style="font-family: inherit;">This section deals with the client request and build with traditional RDBMS+Java based API. This supports the real time querying capability of the API. This system tries to serve the de-normalized data for the RDBMS and handle's the security<span style="font-family: inherit;"> and access control. </span></span><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;">Following is the whole data flow/pipeline stages in the system;</span><br /><h4 style="text-align: left;">1. De-normalization on Hadoop/Hive:</h4>This stage is used to de normalized the data and bring it in a form where it can be easily be served by the RDBMS based Java API.&nbsp; Our system used to perform 4 JOIN operation [between table containing records in order of 100 of millions] and results close to 250 million records. Time taken for this stage was nearly 3 hrs.<br /><br /><a href="https://www.blogger.com/blogger.g?blogID=5454104814334713963" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"></a><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-mi6AeaxsVh0/VGHx8LBxauI/AAAAAAAAAWo/u7weaFmJq5g/s1600/slide1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-mi6AeaxsVh0/VGHx8LBxauI/AAAAAAAAAWo/u7weaFmJq5g/s1600/slide1.png" height="392" width="640" /></a></div><a href="https://www.blogger.com/blogger.g?blogID=5454104814334713963" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"></a><br /><br /><br /><br /><h4 style="text-align: left;">2. Dynamic Partitioning data into various tables:</h4>This stage is&nbsp; partition the data into various Tables based on the type of API caller. Hive helps us to perform this stage in a fault tolerant manner.<br /><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-70X_RDQUeYA/VGHyQjuOTRI/AAAAAAAAAWw/JtlJdO2d-ts/s1600/slide2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-70X_RDQUeYA/VGHyQjuOTRI/AAAAAAAAAWw/JtlJdO2d-ts/s1600/slide2.png" /></a></div><br /><br /><h4 style="text-align: left;">3. Sqoop Export:</h4>This stage helps us to migrate the data from HDFS/Hive to our RDBMS tables. Each export would nearly transfer 1 T.B of data into various tables. As keeping 230 million unused records in RDBMS tables is a nightmare and each data the new snapshot of the data is loaded into the tables, we need to remove previous data. As we all know that Deleting 230 millions records in an RDBMS is not a great idea, and we need to serve the customer in this deletion phase. We came up with a Normal and toggled table approach. We keep the previous day data in normal tables and API request were served by these normal tables. All the Sqoop export comes into the other tables. Once the export is successful we start serving the request from other tables and simply drop the normal tables. This helps us in getting atomicity in the system as Sqoop export usually takes hrs to run and sometime fails in middle. <br /><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-NpSHRDvOCyA/VGHzgaHU6ZI/AAAAAAAAAW8/OIkAopUlJfw/s1600/slide3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-NpSHRDvOCyA/VGHzgaHU6ZI/AAAAAAAAAW8/OIkAopUlJfw/s1600/slide3.png" /></a></div><br /><br /><h4 style="text-align: left;">4. Security Control in RDBMS:</h4>As data now resides in RDBMS, we can easily exploit security controls which a traditional database provides us. Based on the partitions data is exported to various different tables and access control can be added on that table that only same API user can access these tables. This helps in removing cross-referencing problem where one user's data is given to other user using cross referencing.<br /><br /><h4 style="text-align: left;">5. Java API:</h4>Due to dealing with large amount of data, we have followed the following principle's in designing our Java based API<br /><ul style="text-align: left;"><li>Read a bunch of records from DB.</li><li>Process records.</li><li>Stream back to client.</li></ul>Opposed to normal OOP's conventions, we avoided creating any unnecessary objects as generating/storing/GC's millions of objects are too costly operation. e.g: While developing we started getting Java Heap out of memory exception by using String class in place of Character Arrays.<br /><br />&nbsp; <br />&nbsp;&nbsp; <br /><br />P.S: Special thanks to <a href="https://twitter.com/dhruvkapur91">Dhruv Kapur</a> for his help with Photoshop.<br /><br /><br /><br /><br /><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;"><br /></span><span style="font-family: inherit;"><br /></span></div>